# Code Structure Documentation

## üìÅ **File Organization**

```
kth/anomly-detection/
‚îú‚îÄ‚îÄ anomaly_detection.ipynb              # Main notebook implementation
‚îú‚îÄ‚îÄ MVSEC_Anomaly_Detection_Documentation.md  # Comprehensive documentation
‚îú‚îÄ‚îÄ Code_Structure_Documentation.md      # This file
‚îú‚îÄ‚îÄ system_architecture_diagram.py       # Diagram generation script
‚îú‚îÄ‚îÄ data/                               # MVSEC dataset directory
‚îÇ   ‚îú‚îÄ‚îÄ indoor_flying2_data-002.hdf5   # Event data files
‚îÇ   ‚îú‚îÄ‚îÄ indoor_flying3_data-003.hdf5
‚îÇ   ‚îú‚îÄ‚îÄ outdoor_day1_data-008.hdf5
‚îÇ   ‚îî‚îÄ‚îÄ ...                            # Additional MVSEC files
‚îî‚îÄ‚îÄ output/                            # Generated visualizations
    ‚îú‚îÄ‚îÄ system_architecture.png
    ‚îú‚îÄ‚îÄ data_flow_diagram.png
    ‚îú‚îÄ‚îÄ model_architectures.png
    ‚îú‚îÄ‚îÄ anomaly_strategy.png
    ‚îî‚îÄ‚îÄ evaluation_framework.png
```

## üîß **Notebook Cell Structure**

### **Cell Organization Hierarchy**

```
anomaly_detection.ipynb
‚îú‚îÄ‚îÄ üìñ [1] Project Overview & Documentation
‚îú‚îÄ‚îÄ üîß [2] Environment Setup & Imports
‚îú‚îÄ‚îÄ üíæ [3] Data Loading Configuration
‚îú‚îÄ‚îÄ üîÑ [4] Data Pipeline Documentation
‚îú‚îÄ‚îÄ üì• [5] MVSEC Data Loading Functions
‚îú‚îÄ‚îÄ üèóÔ∏è [6] Data Handler Class Implementation
‚îú‚îÄ‚îÄ üé≠ [7] Anomaly Generation Documentation
‚îú‚îÄ‚îÄ üé≤ [8] Anomaly Generator Implementation
‚îú‚îÄ‚îÄ üì¶ [9] Dataset Creation Class
‚îú‚îÄ‚îÄ üß† [10] Neural Architecture Documentation
‚îú‚îÄ‚îÄ ‚ö° [11] Spiking Neural Network Implementation
‚îú‚îÄ‚îÄ üîÑ [12] RNN & TCN Implementation
‚îú‚îÄ‚îÄ üèãÔ∏è [13] Training & Evaluation Framework
‚îú‚îÄ‚îÄ üìä [14] Visualization Functions
‚îú‚îÄ‚îÄ üîó [15] Complete Pipeline Function
‚îú‚îÄ‚îÄ üöÄ [16] Main Execution Pipeline
‚îú‚îÄ‚îÄ üß™ [17] Data Loading Test
‚îî‚îÄ‚îÄ üìã [18] Results & Conclusion
```

## üèóÔ∏è **Class Architecture**

### **Core Classes Hierarchy**

```
Data Processing Layer:
‚îú‚îÄ‚îÄ MVSECDataHandler
‚îÇ   ‚îú‚îÄ‚îÄ __init__(data_path, sequence, camera, sensor_size)
‚îÇ   ‚îú‚îÄ‚îÄ load_data(max_events) ‚Üí events_dict
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_events(events, num_frames) ‚Üí frame_tensor
‚îÇ   ‚îî‚îÄ‚îÄ create_dataset(num_frames, frame_size) ‚Üí processed_frames

Anomaly Generation Layer:
‚îú‚îÄ‚îÄ AnomalyGenerator
‚îÇ   ‚îú‚îÄ‚îÄ __init__(seed)
‚îÇ   ‚îú‚îÄ‚îÄ add_blackout_region(frame, region_size, intensity)
‚îÇ   ‚îú‚îÄ‚îÄ add_vibration_noise(frame, region_size, intensity)
‚îÇ   ‚îú‚îÄ‚îÄ flip_polarities(frame, region_size, flip_prob)
‚îÇ   ‚îî‚îÄ‚îÄ add_random_anomaly(frame, anomaly_type)

Dataset Layer:
‚îú‚îÄ‚îÄ EventAnomalyDataset(Dataset)
‚îÇ   ‚îú‚îÄ‚îÄ __init__(frames, anomaly_ratio, transform)
‚îÇ   ‚îú‚îÄ‚îÄ __len__() ‚Üí int
‚îÇ   ‚îú‚îÄ‚îÄ __getitem__(idx) ‚Üí (frame, label, mask, anomaly_type)
‚îÇ   ‚îî‚îÄ‚îÄ [Pre-generated anomaly storage for efficiency]

Model Layer:
‚îú‚îÄ‚îÄ SpikingAnomalyDetector(nn.Module)
‚îÇ   ‚îú‚îÄ‚îÄ SpikingConv2d layers (3x)
‚îÇ   ‚îú‚îÄ‚îÄ Global average pooling
‚îÇ   ‚îú‚îÄ‚îÄ Linear classification head
‚îÇ   ‚îî‚îÄ‚îÄ reset_membrane_potentials()
‚îÇ
‚îú‚îÄ‚îÄ RNNAnomalyDetector(nn.Module)
‚îÇ   ‚îú‚îÄ‚îÄ Conv2d feature extraction (2x)
‚îÇ   ‚îú‚îÄ‚îÄ GRU temporal processing
‚îÇ   ‚îî‚îÄ‚îÄ Linear classification head
‚îÇ
‚îî‚îÄ‚îÄ TCNAnomalyDetector(nn.Module)
    ‚îú‚îÄ‚îÄ TemporalBlock layers (3x)
    ‚îú‚îÄ‚îÄ Global average pooling
    ‚îî‚îÄ‚îÄ Linear classification head
```

## üîÑ **Function Flow Diagram**

### **Main Pipeline Execution Flow**

```mermaid
graph TD
    A[load_mvsec_data] --> B[MVSECDataHandler.create_dataset]
    B --> C[EventAnomalyDataset.__init__]
    C --> D[random_split]
    D --> E[DataLoader creation]
    E --> F[Model instantiation]
    F --> G[train_model]
    G --> H[test_model]
    H --> I[Visualization & Results]

    B --> B1[load_data]
    B --> B2[preprocess_events]
    B --> B3[Frame resizing]

    C --> C1[AnomalyGenerator.add_random_anomaly]
    C1 --> C2[Pre-generate all anomalies]

    G --> G1[train_one_epoch loop]
    G1 --> G2[evaluate_model]
    G2 --> G3[Learning rate scheduling]
```

## üìä **Data Flow Architecture**

### **Data Transformation Pipeline**

```
Raw MVSEC HDF5 Files
‚îî‚îÄ‚îÄ Format: davis/left/events ‚Üí [x, y, timestamp, polarity] arrays

Event Dictionary Extraction
‚îî‚îÄ‚îÄ Structure: {'x': array, 'y': array, 't': array, 'p': array}

Temporal Binning Process
‚îú‚îÄ‚îÄ Time range division: t_min ‚Üí t_max / num_frames
‚îú‚îÄ‚îÄ Spatial mapping: (x,y) coordinates ‚Üí pixel locations
‚îú‚îÄ‚îÄ Channel separation: polarity (+1/-1) ‚Üí channels (0/1)
‚îî‚îÄ‚îÄ Normalization: raw counts ‚Üí [0, 1] intensity range

Frame Tensor Generation
‚îî‚îÄ‚îÄ Output shape: (num_frames, 2, height, width)
    ‚îú‚îÄ‚îÄ Dimension 0: Temporal sequence (50 frames)
    ‚îú‚îÄ‚îÄ Dimension 1: Polarity channels (pos/neg events)
    ‚îú‚îÄ‚îÄ Dimension 2: Spatial height (64 pixels)
    ‚îî‚îÄ‚îÄ Dimension 3: Spatial width (64 pixels)

Anomaly Injection Process
‚îú‚îÄ‚îÄ Random selection: 50% of frames marked for anomalies
‚îú‚îÄ‚îÄ Anomaly type selection: Uniform distribution across 3 types
‚îú‚îÄ‚îÄ Parameter randomization: Region size, intensity, position
‚îî‚îÄ‚îÄ Mask generation: Binary masks for anomaly localization

Final Dataset Structure
‚îî‚îÄ‚îÄ PyTorch Dataset: (frame_tensor, binary_label, anomaly_mask, anomaly_type)
```

## üßÆ **Algorithm Implementation Details**

### **Spiking Neural Network Algorithm**

```python
# Membrane Potential Dynamics
V[t] = Œ≤ * V[t-1] + I[t]              # Leaky integration
S[t] = Heaviside(V[t] - Œ∏)            # Spike generation
V[t] = V[t] - S[t] * Œ∏                # Reset after spike

# Surrogate Gradient for Backpropagation
‚àÇS/‚àÇV = Œ± * exp(-Œ±|V-Œ∏|) / (1 + exp(-Œ±(V-Œ∏)))¬≤

# Where:
# Œ≤ = membrane decay factor (0.9)
# Œ∏ = firing threshold (1.0)
# Œ± = surrogate gradient steepness (10.0)
# I[t] = input current from previous layer
```

### **Temporal Binning Algorithm**

```python
# Event-to-Frame Conversion Process
for each event (x, y, t, p):
    bin_index = floor((t - t_min) / bin_width)
    channel = 0 if p == +1 else 1
    frame[bin_index, channel, y, x] += 1

# Normalization per frame and channel
for frame_idx in range(num_frames):
    for channel in range(2):
        max_val = frame[frame_idx, channel].max()
        if max_val > 0:
            frame[frame_idx, channel] /= max_val
```

### **Anomaly Injection Algorithm**

```python
# Systematic Anomaly Generation
def generate_balanced_dataset(frames, anomaly_ratio=0.5):
    num_anomalies = int(len(frames) * anomaly_ratio)
    anomaly_indices = random.choice(len(frames), num_anomalies)

    for idx in anomaly_indices:
        anomaly_type = random.choice(['blackout', 'vibration', 'flip'])
        frame[idx], mask[idx] = apply_anomaly(frame[idx], anomaly_type)

    return labeled_dataset
```

## üéØ **Performance Optimization Strategies**

### **Memory Management**

1. **Event Sampling**: Limit to 500K events per sequence
   ```python
   if total_events > max_events:
       indices = np.linspace(0, total_events-1, max_events, dtype=int)
       events = {key: events[key][indices] for key in events}
   ```

2. **Batch Processing**: Small batch sizes (8-16) for memory efficiency
   ```python
   train_loader = DataLoader(dataset, batch_size=8, shuffle=True)
   ```

3. **Pre-computation**: Generate all anomalies during dataset creation
   ```python
   # Pre-generate anomalies in __init__ rather than __getitem__
   self.anomaly_frames = [self.generate_anomaly(frame) for frame in frames]
   ```

### **Computational Efficiency**

1. **Spatial Downsampling**: 260√ó346 ‚Üí 64√ó64 resolution
2. **Temporal Compression**: ~25M events ‚Üí 50 frame sequence
3. **Channel Optimization**: Separate pos/neg processing pipelines
4. **Model Simplification**: Focused architectures with minimal parameters

### **Training Optimization**

1. **Learning Rate Scheduling**: ReduceLROnPlateau for convergence
2. **Early Stopping**: Validation loss monitoring
3. **Gradient Clipping**: Prevent exploding gradients in SNN
4. **Memory Reset**: Clear SNN membrane states between batches

## üîç **Error Handling & Robustness**

### **Data Loading Robustness**

```python
try:
    events, sensor_size = load_mvsec_data(data_path, sequence, camera)
except FileNotFoundError:
    raise ValueError(f"MVSEC data not found in {data_path}")
except KeyError as e:
    raise ValueError(f"Invalid HDF5 structure: missing {e}")
except Exception as e:
    logger.error(f"Unexpected error loading data: {e}")
    raise
```

### **Training Stability**

```python
# SNN-specific stability measures
if isinstance(model, SpikingAnomalyDetector):
    loss.backward(retain_graph=True)  # Handle graph connectivity
    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
else:
    loss.backward()
```

### **Memory Management**

```python
# Explicit cleanup for large datasets
del events, frames  # Clear intermediate variables
torch.cuda.empty_cache()  # GPU memory cleanup
gc.collect()  # Python garbage collection
```

## üìà **Extensibility & Modularity**

### **Adding New Anomaly Types**

```python
class AnomalyGenerator:
    def add_custom_anomaly(self, frame, **params):
        """Template for new anomaly types"""
        modified_frame = frame.clone()
        anomaly_mask = torch.zeros_like(frame[0], dtype=torch.bool)

        # Custom anomaly implementation here

        return modified_frame, anomaly_mask

    def register_anomaly_type(self, name, function):
        """Dynamic anomaly registration"""
        self.anomaly_types[name] = function
```

### **Adding New Model Architectures**

```python
class NewArchitectureDetector(nn.Module):
    """Template for additional neural architectures"""
    def __init__(self, input_channels, **kwargs):
        super().__init__()
        # Architecture-specific initialization

    def forward(self, x):
        # Architecture-specific forward pass
        return output
```

### **Configuration Management**

```python
# Centralized configuration dictionary
CONFIG = {
    'data': {
        'sequence': 'indoor_flying',
        'camera': 'left',
        'max_events': 500000,
        'sensor_size': (64, 64),
        'num_frames': 50
    },
    'training': {
        'batch_size': 8,
        'num_epochs': 10,
        'learning_rate': 0.001,
        'anomaly_ratio': 0.5
    },
    'models': {
        'snn': {'beta': 0.9, 'threshold': 1.0},
        'rnn': {'hidden_dim': 64},
        'tcn': {'hidden_channels': [16, 32, 64]}
    }
}
```

## üß™ **Testing & Validation Framework**

### **Unit Testing Structure**

```python
def test_data_loading():
    """Test MVSEC data loading functionality"""
    events, sensor_size = load_mvsec_data('./test_data', 'indoor_flying', 'left')
    assert len(events['x']) > 0
    assert sensor_size == (260, 346)

def test_anomaly_generation():
    """Test anomaly injection methods"""
    frame = torch.rand(2, 64, 64)
    anomaly_frame, mask = add_blackout_region(frame, (20, 20))
    assert not torch.equal(frame, anomaly_frame)
    assert mask.sum() > 0

def test_model_forward_pass():
    """Test model forward propagation"""
    model = SpikingAnomalyDetector(input_channels=2)
    input_tensor = torch.rand(4, 2, 64, 64)
    output = model(input_tensor)
    assert output.shape == (4, 2)
```

### **Integration Testing**

```python
def test_end_to_end_pipeline():
    """Test complete pipeline execution"""
    results = run_mvsec_anomaly_detection_pipeline(
        data_path='./test_data',
        num_epochs=1,
        num_frames=5
    )
    assert results is not None
    assert 'models' in results
    assert 'metrics' in results
```

This comprehensive code structure documentation provides a complete blueprint for understanding, extending, and maintaining the anomaly detection system.
